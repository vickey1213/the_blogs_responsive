{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"content\": \"Hello! How can I assist you today?\",\n",
      "  \"role\": \"assistant\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from nextpy.ai.models.llm import OpenAI\n",
    "\n",
    "llm = OpenAI(api_key='sk-enter-api-key') # Replace with your API key\n",
    "openai_response = llm.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo-0613\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Hello!\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Print the OpenAI response\n",
    "print(openai_response[\"choices\"][0][\"message\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nextpy.ai import engine as guidance\n",
    "# set Openai API key\n",
    "api_key = 'sk-enter-api-key'\n",
    "\n",
    "model = guidance.llms.OpenAI(\"gpt-3.5-turbo\", chat_mode=True, api_key=api_key, caching=False)\n",
    "# vicuna = guidance.llms.transformers.Vicuna(\"your_path/vicuna_13B\", device_map=\"auto\")\n",
    "example = guidance('''\n",
    " {{#system~}}\n",
    "        You are a helpful assistant\n",
    "        {{~/system}}\n",
    "\n",
    "        {{~#geneach 'conversation' stop=False}}\n",
    "        {{#user~}}\n",
    "        {{set 'this.user_text' (await 'user_text')  hidden=False}}\n",
    "        {{~/user}}\n",
    "\n",
    "        {{#assistant~}}\n",
    "        {{gen 'this.ai_text' temperature=0 max_tokens=300}}\n",
    "        {{~/assistant}}\n",
    "        {{~/geneach}}\n",
    "''', llm=model)\n",
    "\n",
    "output = example(user_text= \"hello\")\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nextpy.ai import engine\n",
    "from nextpy.ai.engine.llms import OpenAI\n",
    "\n",
    "# Set Azure OpenAI API key and Endpoint\n",
    "azure_api_key = \"\"\n",
    "azure_endpoint = \"\"  # Typically in the format \"https://api.openai.com\"\n",
    "\n",
    "# Initialize the Azure OpenAI model\n",
    "model = engine.llms.AzureOpenAILLM(\"gpt-35-turbo-16k-dec\", chat_mode=True, api_key=azure_api_key, api_base=azure_endpoint, caching=False)\n",
    "\n",
    "example = engine('''\n",
    "{{#system~}}\n",
    "You are a knowledgeable and efficient assistant.\n",
    "{{~/system}}\n",
    "\n",
    "{{#user~}}\n",
    "Please analyze the following question:\n",
    "{{query}}\n",
    "Identify the exact topic and user intent in one sentence.\n",
    "{{~/user}}\n",
    "\n",
    "{{#assistant~}}\n",
    "{{gen 'topic_intent' temperature=0 max_tokens=50}}\n",
    "{{~/assistant}}\n",
    "''', llm=model)\n",
    "\n",
    "output = example(query=\"What is the capital of the Netherlands?\")\n",
    "\n",
    "print(output['topic_intent'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dotagent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
